= Spark

1) Установите Spark локально на операционную систему.

2) Запустите интепретатор Scala/Python и выполнить простой код (например, подсчет количества слов в тексте)

[source,scala]
----
val text = "Hello world"

val wordCounts = text.split(" ")
  .groupBy(identity)
  .mapValues(_.length)

println(wordCounts)
----


3) При помощи встроенных средств выведите информацию о Spark в консоль


image::imgs/image-2025-04-17-22-54-59-727.png[]

4) Выведите web-страницу с информацией о Spark и его текущей загрузке

image::imgs/image-2025-04-17-23-01-33-685.png[]

5) Установите Spark на кластер Hadoop, созданный в предыдущей практической работе

image::imgs/image-2025-04-17-23-20-40-111.png[]

6)	При помощи встроенных средств выведите информацию о Spark в консоль

[source,bash]
----
spark-submit --version
----

image::imgs/image-2025-04-17-23-24-20-136.png[]

7) Выведите web-страницу с информцией о Spark и его текущей загрузке

8) Сконфигуруйте и подготовьте к работе Spark SQL

